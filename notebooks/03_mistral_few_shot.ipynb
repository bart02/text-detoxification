{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108165a3-c512-47c2-b4e4-34060351cf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install transformers accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7a2981f-21c9-44e6-aa83-e39e0a4cad89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" # the device to load the model onto\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2098648d-810f-4726-a87d-e79eaabb4cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7af737f-4c46-42a9-b2f9-762a529edd57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0b57492cb8046d1b2936e8d74bf67a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\", device_map=\"auto\", torch_dtype=torch.float16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "bcfdfa60-0259-4bc1-98de-0995ceb2b1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Make text NON TOXIC according to the examples. Write ONLY Non-toxic text as an output! It could not be no response. \\n Toxic text: he's a liar who doesn't drink, he doesn't smoke, he doesn't go for women.\\nNon-toxic text: \"}\n",
    "]\n",
    "\n",
    "inp = '''[INST] Make text NON TOXIC according to the examples. Write ONLY Non-toxic text as an output! It could not be no response. [/INST] \n",
    "Toxic text: Bourne will be useless to me as a dead man.\n",
    "Non-toxic text: Bourne dead gives me nothing.\n",
    "\n",
    "Toxic text: You know, I understand the whole entourage thing, but I don't get why a nice guy like Scott has to hang out with those two parasites.\n",
    "Non-toxic text: you know, I get the whole thing with the escort, but I don't understand why a nice guy like Scott is throwing two parasions with them.\n",
    "\n",
    "Toxic text: I think he'd go home not feeling like a piece of crap.\n",
    "Non-toxic text: I think he would go home and he didn't feel like an onuce.\n",
    "\n",
    "Toxic text: Just because you break into people's homes... doesn't mean you have to look like a fucking burglar.\n",
    "Non-toxic text: '''\n",
    "\n",
    "encodeds = tokenizer(inp, return_tensors=\"pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "68f5f103-aa03-4797-aed6-4476eebfd004",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_inputs = encodeds.to(device)\n",
    "\n",
    "generated_ids = model.generate(**model_inputs, max_new_tokens=100, do_sample=True, eos_token_id=[2, 13], temperature=1.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0be2afa3-2b0c-4b6a-b4c4-33df423dbec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1You enter into people spaces without permission and invinceing that 2you shouldn't have look like a 1thief\n"
     ]
    }
   ],
   "source": [
    "decoded = tokenizer.batch_decode(generated_ids[:, model_inputs[\"input_ids\"].shape[1]:], skip_special_tokens=True)\n",
    "print(decoded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3272851-06d4-48d3-8242-1873c4a9fbb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    1,   733, 16289, 28793,  6746,  2245,   418,   832,  6991, 28814,\n",
       "          1604,  4771,   298,   272,  9254, 28723, 12018,  9688,  9880,  9187,\n",
       "         28733,   532, 14443,  2245,   390,   396,  3825, 28808,   661,   829,\n",
       "           459,   347,   708,  2899, 28723, 28705,    13,   320,  1142,   294,\n",
       "          2245, 28747,   400, 28742, 28713,   264,   635,   283,   693,  2368,\n",
       "         28742, 28707,  4663, 28725,   400,  2368, 28742, 28707, 10619, 28725,\n",
       "           400,  2368, 28742, 28707,   576,   354,  2525, 28723,    13,  7525,\n",
       "         28733,   532, 14443,  2245, 28747, 28705,   733, 28748, 16289, 28793]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ef430d1f-cfea-4f51-b539-b4592b5ab89c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  851,  1338, 17154,  1606,   477,  6288,   288, 11070,   304, 26865,\n",
       "           304,   349,   459,  6348,   297, 16534,  9391, 28723,     2]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_ids[:, model_inputs.shape[1]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aea0a724-5d37-4d45-8a90-c2faec7e45e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerationConfig {\n",
       "  \"bos_token_id\": 1,\n",
       "  \"eos_token_id\": 2\n",
       "}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e0c7b354-1bc4-4df3-8a23-6d851f318047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [1, 28705, 13], 'attention_mask': [1, 1, 1]}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "773e24e1-cc7e-4ff1-a160-f0a2ef2b060f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78b14d3-f370-4519-8b1f-a6f31b84ebc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
